{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is to used the \"Imagenet\" dataset and make a dataset containing food and non food images. But Imagenet is not pre divided into these two catagories. So the goal is to use the class labels of imagenet dataset and compare them with food nouns extracted from \"Wordnet\" dataset and dividing the Imagenet by iterating though the class labels and cross checking it with the founnd food nouns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Making a dictionary of ImageNet Class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_classes = []\n",
    "with open(\"imagenet1000_clsidx_to_labels.txt\", \"r\") as f:\n",
    "  imagenet_classes = ast.literal_eval(f.read())    #literal_eval raises an exception if the input isn't a valid Python datatype, so the code won't be executed if \n",
    "  #it's not. This load all the class names in imagenet and make a dictionary out of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n"
     ]
    }
   ],
   "source": [
    "for k,v in imagenet_classes.items(): #iterating through class labels and checking a specific label is available or not.\n",
    "  if \"chocolate\" in v:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extracting Food Nouns from WordNet Dataset Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\94768\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\94768\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followoing function compares a given word with the Wordnet dataset and outputs 1 if it is associated to a food item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_not_food(word):        #Returns 0 or 1 whether a string is a food noun or not.\n",
    "    syns = wn.synsets(str(word), pos=wn.NOUN)  #search for the specific word in the dataset\n",
    "    for syn in syns:\n",
    "        if \"food\" in syn.lexname(): #lexname has 3 tab seperated fields describing the word. \n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of words containing boath food and nonfoods are taken from the words.txt and the words in this is sent to food_not_food fuction to divide them into two catagories. A different word set is used for this rather than using the Imagenet classes list because that contains more than one word describing each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = pd.read_csv(\"Data\\words.txt\", header=None)\n",
    "word_list.columns = [\"word\"]   #Naming the column containing words as the \"word\" column\n",
    "word_list[\"is_food\"] = word_list[\"word\"].apply(food_not_food)   #New column mentioning the item as food or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_list = word_list[word_list[\"is_food\"]==1][\"word\"].tolist() #Making a new list of \"word\"s if the \"is_food\" column in word_list is 1.as_integer_ratio\n",
    "non_food_list = word_list[word_list[\"is_food\"]==0][\"word\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(file, list):    #function to write whats in a list to a file with each entry in new line.\n",
    "  with open(file, 'w') as f:\n",
    "    for i in list:\n",
    "      f.write(str(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(\"Data/food_list.txt\", food_list)\n",
    "write_to_file(\"Data/non_food_list.txt\", non_food_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b650c002c9c7f4ac77ececf3c6b3e6609799feafcdff157b0e56892c01665889"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
